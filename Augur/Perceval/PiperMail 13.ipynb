{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import augur\n",
    "from augur.piper_reader import PiperMail\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import json\n",
    "import pandas as pd\n",
    "from perceval.backends.core.pipermail import Pipermail,PipermailList\n",
    "from perceval.backends.core.mbox import MBox\n",
    "import perceval\n",
    "import os, os.path\n",
    "import sqlalchemy as s\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import datetime\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load:\n",
    "First loads the users data from 'augur.config.json' so will take the Database information (e.g. name of database, port of database). Then connects to the database using augur.App.ghtorrentplus() and also loads the piper_reader and loads the path to the list of mailing lists 'runtine/mailing_lists.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(\"notebooks\" not in os.getcwd()):\n",
    "    os.chdir(\"notebooks\")\n",
    "augurApp = augur.Application('../augur.config.json')\n",
    "connect = augurApp.ghtorrentplus()\n",
    "Piper, path= augurApp.piper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect:\n",
    "\n",
    "Queries what tables are in the database and determines if 'mail_lists' is there if it is 'mail_lists' is set as 'True' if it isn't 'mail_lists' is set at 'False'. Then we determine what mailing lists are in 'mailing_list_jobs' and we determine how many rows are in it. If 'mailing_list_jobs' is not in the Database it is created and the column 'augurlistID' is set as the primary key. We then add a connection to 'mailing_list_jobs' so that we can change the column 'last_message_date' if new messages were downloaded for a mailing list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github_issues', 'github_issues_sentiment_scores', 'github_pull_requests', 'github_pull_requests_sentiment_scores', 'github_repo_jobs', 'issue_response_time']\n",
      "Created Table\n"
     ]
    }
   ],
   "source": [
    "table_names = s.inspect(connect.db).get_table_names()\n",
    "print(table_names)\n",
    "val = False\n",
    "mail_lists = True\n",
    "numb = 0\n",
    "if(\"mail_lists\" not in table_names):\n",
    "    mail_lists = False\n",
    "if(\"mailing_list_jobs\" in table_names):\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM mailing_list_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, connect.db)\n",
    "    print(df1)\n",
    "    val = True\n",
    "    val = connect.db.engine.execute(\"\"\"SELECT augurlistID FROM \n",
    "                                   mailing_list_jobs\n",
    "                                   ORDER BY augurlistID DESC LIMIT 1\"\"\")\n",
    "    for i in val:\n",
    "        numb = i['augurlistID']\n",
    "    \n",
    "else:\n",
    "    columns2 = \"augurlistID\",\"backend_name\",\"mailing_list_url\",\"project\",\"last_message_date\"\n",
    "    df_mail_list = pd.DataFrame(columns=columns2)\n",
    "    df_mail_list.to_sql(name=\"mailing_list_jobs\",con=connect.db,if_exists='replace',index=False,\n",
    "                        dtype={'augurlistID': s.types.Integer(),\n",
    "                               'backend_name': s.types.VARCHAR(length=300),\n",
    "                               'mailing_list_url': s.types.VARCHAR(length=300),\n",
    "                               'project': s.types.VARCHAR(length=300),\n",
    "                               'last_message_date': s.types.DateTime()\n",
    "                        })\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM mailing_list_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, connect.db)\n",
    "    connect.db.execute(\"ALTER TABLE mailing_list_jobs ADD PRIMARY KEY (augurlistID)\")\n",
    "    print(\"Created Table\")\n",
    "Base = declarative_base(connect.db)\n",
    "class table(Base):\n",
    "    __tablename__ = 'mailing_list_jobs'\n",
    "    __table_args__={'autoload':True}\n",
    "    \n",
    "Session = sessionmaker(bind=connect.db)\n",
    "session = Session()\n",
    "res = session.query(table).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sifting through messages:\n",
    "\n",
    "The function 'write_message' is used to fetch the messages from the downloaded MBox's. The messages downloaded can either be from the last message was downloaded when the jupyter notebook was downloaded previously or if it's the first time all the messages are downloaded. The function 'write_message' then determines which message contains the full message thread by looking to see if the 'ID' for the message is stored in 'References'. Only if the next message downloaded does not reference the previous message will the message be added to dictionary and if a certain amount of messages are stored it is added to the table 'mail_lists' using piper_reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_message(repo,type_archive,mail_check,pos,db,res,session,archives,numb,mail_lists,time=None):\n",
    "    thread = None\n",
    "    store = None\n",
    "    k = 0\n",
    "    di = {}\n",
    "    for message in repo.fetch(from_date=time):\n",
    "        if(type_archive == 'not_new'):\n",
    "            mess_check = Piper.convert_date(message['data']['Date'])\n",
    "        if(type_archive == 'not_new' and mess_check <= time ):\n",
    "            continue            \n",
    "        elif(type_archive == 'not_new' and mess_check > time):\n",
    "            mail_check[pos] = 'update'\n",
    "            \n",
    "        ID = message['data']['Message-ID']\n",
    "        try:\n",
    "            message['data']['References']                           \n",
    "            if((not thread == None) and (thread['data']['Message-ID'] not in message['data']['References'])):\n",
    "                di[k] = thread\n",
    "                store = None\n",
    "                k+=1\n",
    "                \n",
    "            elif( (not store == None) and (store['data']['Message-ID'] not in message['data']['References'])):\n",
    "                di[k] = store\n",
    "                store = None\n",
    "                k+=1\n",
    "            thread = message\n",
    "        except:\n",
    "            if(not thread == None):\n",
    "                di[k] = thread\n",
    "                thread = None\n",
    "                k+=1\n",
    "            elif(not store == None):\n",
    "                di[k] = store\n",
    "                store = None\n",
    "                k+=1\n",
    "            store = message\n",
    "        if(len(di) == 5000):\n",
    "            numb,mail_lists = Piper.make(connect.db,mail_check,archives,mail_lists,res,session,di,numb)\n",
    "            di = {}\n",
    "            k = 0\n",
    "    if(len(di) < 5000 and len(di) > 0):\n",
    "        print(len(di))\n",
    "        numb,mail_lists = Piper.make(connect.db,mail_check,archives,mail_lists,res,session,di,numb)\n",
    "        di = {}\n",
    "        k = 0\n",
    "    else:\n",
    "        di = {}\n",
    "        k = 0\n",
    "    if( (thread == None) and (store == None)):\n",
    "        good = 1\n",
    "    elif( (thread == None) and (not store == None) ):\n",
    "        di[k] = store\n",
    "    elif( (store == None) and (not thread == None)):\n",
    "        di[k] = thread\n",
    "    elif(store['data']['Message-ID'] in thread['data']['References']):\n",
    "        di[k] = thread\n",
    "    else:\n",
    "        di[k] = store\n",
    "    if(bool(di)):\n",
    "        numb,mail_lists = Piper.make(connect.db,mail_check,archives,mail_lists,res,session,di,numb)\n",
    "    return numb,mail_lists\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration through mailing lists:\n",
    "\n",
    "Determines if the file with the mailing lists was created, if not it writes a set of default mailing lists (to show how the program would work). The mailing lists are then loaded into a dataframe and we iterate through the mailing lists by grouping them by the links. We then check to see if the mailing list is in the 'mailing_list_jobs' table in the SQL Database and if so we assign 'not_new' to 'mail_check' and store the last message date that is stored in 'mailing_list_jobs' to 'time'. If the mailing list is not in 'mailing_list_jobs' we assign 'new' to 'mail_check' and the date is set to 'None' for 'time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 16:50:02 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Looking for messages from 'https://lists.opendaylight.org/pipermail/aalldp-dev/' since 1970-01-01 00:00:00+00:00\n",
      "2018-08-01 16:50:02 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Downloading mboxes from 'https://lists.opendaylight.org/pipermail/aalldp-dev/' to since 1970-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime/mailing_lists.csv Place\n",
      "yeah\n",
      "Link,mail_list\n",
      "\n",
      "https://lists.opendaylight.org/pipermail/,\"aalldp-dev\"\n",
      "\n",
      "['aalldp-dev', 'archetypes-dev'] mail_list\n",
      "{'aalldp-dev': False, 'archetypes-dev': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 16:50:07 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO 2/2 MBoxes downloaded\n",
      "2018-08-01 16:50:07 keanu-Inspiron-5567 perceval.backends.core.mbox[18033] INFO Done. 6/6 messages fetched; 0 ignored\n",
      "2018-08-01 16:50:07 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Fetch process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "getting\n",
      "yep\n",
      "got-em\n",
      "4\n",
      "['aalldp-dev']\n",
      "2018-07-06 18:39:58\n",
      "File uploaded  13\n",
      "Mailing List Job uploaded\n",
      "Finished\n",
      "['aalldp-dev']\n",
      "File uploaded  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 16:50:31 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Looking for messages from 'https://lists.opendaylight.org/pipermail/archetypes-dev/' since 1970-01-01 00:00:00+00:00\n",
      "2018-08-01 16:50:31 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Downloading mboxes from 'https://lists.opendaylight.org/pipermail/archetypes-dev/' to since 1970-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mailing List Job uploaded\n",
      "Finished\n",
      "Created File aalldp-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 16:50:33 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO 1/1 MBoxes downloaded\n",
      "2018-08-01 16:50:33 keanu-Inspiron-5567 perceval.backends.core.mbox[18033] INFO Done. 2/2 messages fetched; 0 ignored\n",
      "2018-08-01 16:50:33 keanu-Inspiron-5567 perceval.backends.core.pipermail[18033] INFO Fetch process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "1\n",
      "['archetypes-dev']\n",
      "File uploaded  4\n",
      "Mailing List Job uploaded\n",
      "Finished\n",
      "['archetypes-dev']\n",
      "File uploaded  4\n",
      "Mailing List Job uploaded\n",
      "Finished\n",
      "Created File archetypes-dev\n",
      "{'aalldp-dev': 'new', 'archetypes-dev': 'new'}\n",
      "Finished downloading files\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.exists(path)):\n",
    "    file = open(path, \"w+\")\n",
    "else:\n",
    "    file = open(path, \"r\")\n",
    "    print(\"yeah\")\n",
    "if (os.stat(path).st_size == 0):\n",
    "    file.write(\"Link,mail_list\\n\")\n",
    "    file.write(\"https://lists.opendaylight.org/pipermail/,\\\"aalldp-dev\\\"\\n\")\n",
    "    file.write(\"https://lists.opendaylight.org/pipermail/,\\\"archetypes-dev\\\"\\n\")\n",
    "    print(\"Please enter the mailing lists and the links for them please\")\n",
    "    print(\"Going to the default mailing lists\")\n",
    "\n",
    "count = 0\n",
    "for line in file:\n",
    "    print(line)\n",
    "    count+=1\n",
    "    if(count == 2):\n",
    "        break\n",
    "if(count == 2):\n",
    "    file.close()\n",
    "    df = pd.read_csv(path)\n",
    "    groups = df.groupby('Link').groups\n",
    "    for group in groups:\n",
    "        link = group\n",
    "        mail_list = (df.loc[df['Link'] == group]['mail_list']).tolist()\n",
    "        print(mail_list,\"mail_list\")            \n",
    "        mail_check = {key:False for key in mail_list}\n",
    "        print(mail_check)\n",
    "        file = \"mail_list\"\n",
    "        path = \"/augur/data/archive-\" \n",
    "        #numb = 0\n",
    "        for x in range(len(mail_list)):\n",
    "            #print(link+mail[x])\n",
    "            if(mail_list[x] not in df1['project'].values ):\n",
    "                mail_check[mail_list[x]] = 'new'\n",
    "                place = os.path.join(os.getcwd() + path + mail_list[x] +'.json')           \n",
    "                repo = Pipermail(url = link+ mail_list[x] + \"/\",dirpath=\"tmp/archives_\"+mail_list[x])\n",
    "                numb,mail_lists = write_message(repo,'new',mail_check,mail_list[x],connect.db,res,session,\\\n",
    "                                     [mail_list[x]],numb,mail_lists)\n",
    "                print(\"Created File\",mail_list[x])\n",
    "            else:\n",
    "                last_updatedSQL = s.sql.text(\"\"\"SELECT last_message_date FROM \n",
    "                mailing_list_jobs WHERE project = \"\"\" +  \"'\" + mail_list[x] + \"'\")\n",
    "                last_updated_df = pd.read_sql(last_updatedSQL, connect.db)\n",
    "                time = (last_updated_df['last_message_date'])  \n",
    "                time = time.astype(object)\n",
    "                place = os.path.join(os.getcwd() + path + 'temp_' + mail_list[x] +'.json')       \n",
    "                repo = Pipermail(url = link+ mail_list[x] + \"/\",dirpath=\"tmp/archives_\"+mail_list[x])\n",
    "                print(time[0])\n",
    "                print(type(time[0]))\n",
    "                numb,mail_lists = write_message(repo,'not_new',mail_check,mail_list[x],connect.db,\\\n",
    "                              res,session,[mail_list[x]],numb,mail_lists,time[0])\n",
    "                print(\"Checking to see for updated messages\")\n",
    "        print(mail_check)\n",
    "        print(\"Finished downloading files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (augur)",
   "language": "python",
   "name": "augur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
