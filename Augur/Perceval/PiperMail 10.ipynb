{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import augur\n",
    "from augur.PiperReader import PiperMail\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "# import everything from githubapi.py and ghtorrent.py so we can\n",
    "# just copy and paste our function later\n",
    "import json\n",
    "import pandas as pd\n",
    "from perceval.backends.core.pipermail import Pipermail,PipermailList\n",
    "from perceval.backends.core.mbox import MBox\n",
    "import perceval\n",
    "import os, os.path\n",
    "import sqlalchemy as s\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import datetime\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(\"notebooks\" not in os.getcwd()):\n",
    "    os.chdir(\"notebooks\")\n",
    "augurApp = augur.Application('../augur.config.json')\n",
    "connect = augurApp.ghtorrentplus()\n",
    "Piper, path= augurApp.piper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect.db.execute(\"\"\"DROP TABLE mailing_list_jobs\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github_issues', 'issue_response_time', 'mail_lists_sentiment_scores']\n",
      "Created Table\n"
     ]
    }
   ],
   "source": [
    "table_names = s.inspect(connect.db).get_table_names()\n",
    "print(table_names)\n",
    "val = False\n",
    "mail_lists = True\n",
    "numb = 0\n",
    "if(\"mail_lists\" not in table_names):\n",
    "    mail_lists = False\n",
    "if(\"mailing_list_jobs\" in table_names):\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM mailing_list_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, connect.db)\n",
    "    print(df1)\n",
    "    val = True\n",
    "    val = connect.db.engine.execute(\"\"\"SELECT augurlistID FROM \n",
    "                                   mailing_list_jobs\n",
    "                                   ORDER BY augurlistID DESC LIMIT 1\"\"\")\n",
    "    for i in val:\n",
    "        numb = i['augurlistID']\n",
    "    \n",
    "else:\n",
    "    columns2 = \"augurlistID\",\"backend_name\",\"mailing_list_url\",\"project\",\"last_message_date\"\n",
    "    df_mail_list = pd.DataFrame(columns=columns2)\n",
    "    df_mail_list.to_sql(name=\"mailing_list_jobs\",con=connect.db,if_exists='replace',index=False,\n",
    "                        dtype={'augurlistID': s.types.Integer(),\n",
    "                               'backend_name': s.types.VARCHAR(length=300),\n",
    "                               'mailing_list_url': s.types.VARCHAR(length=300),\n",
    "                               'project': s.types.VARCHAR(length=300),\n",
    "                               'last_message_date': s.types.DateTime()\n",
    "                        })\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM mailing_list_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, connect.db)\n",
    "    connect.db.execute(\"ALTER TABLE mailing_list_jobs ADD PRIMARY KEY (augurlistID)\")\n",
    "    print(\"Created Table\")\n",
    "Base = declarative_base(connect.db)\n",
    "class table(Base):\n",
    "    __tablename__ = 'mailing_list_jobs'\n",
    "    __table_args__={'autoload':True}\n",
    "    \n",
    "Session = sessionmaker(bind=connect.db)\n",
    "session = Session()\n",
    "res = session.query(table).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_message(repo,type_archive,mail_check,pos,db,res,session,archives,numb,mail_lists,time=None):\n",
    "    thread = None\n",
    "    store = None\n",
    "    k = 0\n",
    "    di = {}\n",
    "    #print(\"HEREEEE\")\n",
    "    if(pos == \"lkml\"):\n",
    "        time = Piper.convert_date(\"Thu, 1 Jan 2013 20:37:11 +0000\")\n",
    "    for message in repo.fetch(from_date=time):\n",
    "        #print(message,\"\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "        #print(message['data']['Message-ID'])\n",
    "        if(type_archive == 'not_new'):\n",
    "            mess_check = Piper.convert_date(message['data']['Date'])\n",
    "            #mess_check = Piper.convert_date(\"Thu, 24 Mar 2019 20:37:11 +0000\")\n",
    "            #print(time)\n",
    "        if(type_archive == 'not_new' and mess_check <= time ):\n",
    "            print(\"Right here\")\n",
    "            continue            \n",
    "        elif(type_archive == 'not_new' and mess_check > time):\n",
    "            mail_check[pos] = 'update'\n",
    "            \n",
    "        ID = message['data']['Message-ID']\n",
    "        try:\n",
    "            message['data']['References']\n",
    "            '''if(message['data']['Message-ID'] == '<CAFHD1sO814do11F9cKVZgr5fo+dw5q-VmfrYO_Q9vv6kXe8NjA@mail.gmail.com>'):\n",
    "                print(thread)\n",
    "                print(store)'''                             \n",
    "            if((not thread == None) and (thread['data']['Message-ID'] not in message['data']['References'])):\n",
    "                #bj = json.dumps(thread, indent=4, sort_keys=True)\n",
    "                di[k] = thread\n",
    "                #utfile.write(obj)\n",
    "                #utfile.write('\\n')\n",
    "                store = None\n",
    "                k+=1\n",
    "                print(\"why\")\n",
    "                \n",
    "            elif( (not store == None) and (store['data']['Message-ID'] not in message['data']['References'])):\n",
    "                #print(message['data']['References'])\n",
    "                di[k] = store\n",
    "                #bj = json.dumps(store, indent=4, sort_keys=True)\n",
    "                #utfile.write(obj)\n",
    "                #utfile.write('\\n')\n",
    "                store = None\n",
    "                print(\"yep\")\n",
    "                k+=1\n",
    "            thread = message\n",
    "        except:\n",
    "            #print(\"got'em\")\n",
    "            if(not thread == None):\n",
    "                di[k] = thread\n",
    "                #bj = json.dumps(thread, indent=4, sort_keys=True)\n",
    "                #utfile.write(obj)\n",
    "                #utfile.write('\\n')\n",
    "                thread = None\n",
    "                print(\"got-em\")\n",
    "                k+=1\n",
    "            elif(not store == None):\n",
    "                di[k] = store\n",
    "                #bj = json.dumps(store, indent=4, sort_keys=True)\n",
    "                #utfile.write(obj)\n",
    "                #utfile.write('\\n')\n",
    "                store = None\n",
    "                print(\"getting\") \n",
    "                k+=1\n",
    "            store = message\n",
    "        if(len(di) == 5000):\n",
    "            numb,mail_lists = Piper.make(connect.db,mail_check,archives,mail_lists,res,session,di,numb)\n",
    "            di = {}\n",
    "            k = 0\n",
    "        #print(\"!\"*50,\"NEW MESSAGE\",\"!\"*50)\n",
    "    if(len(di) < 5000 and len(di) > 0):\n",
    "        print(len(di))\n",
    "        #print(di)\n",
    "        numb,mail_lists = Piper.make(connect.db,mail_check,archives,mail_lists,res,session,di,numb)\n",
    "        di = {}\n",
    "        k = 0\n",
    "    else:\n",
    "        di = {}\n",
    "        k = 0\n",
    "    if( (thread == None) and (store == None)):\n",
    "        good = 1\n",
    "    elif( (thread == None) and (not store == None) ):\n",
    "        di[k] = store\n",
    "        #obj = json.dumps(store, indent=4, sort_keys=True)\n",
    "        #outfile.write(obj)\n",
    "        #outfile.write('\\n')\n",
    "    elif( (store == None) and (not thread == None)):\n",
    "        di[k] = thread\n",
    "        #obj = json.dumps(thread, indent=4, sort_keys=True)\n",
    "        #outfile.write(obj)\n",
    "        #outfile.write('\\n')\n",
    "    elif(store['data']['Message-ID'] in thread['data']['References']):\n",
    "        di[k] = thread\n",
    "        #obj = json.dumps(thread, indent=4, sort_keys=True)\n",
    "        #outfile.write(obj)\n",
    "        #outfile.write('\\n')\n",
    "    else:\n",
    "        di[k] = store\n",
    "        #obj = json.dumps(store, indent=4, sort_keys=True)\n",
    "        #outfile.write(obj)\n",
    "        #outfile.write('\\n')  \n",
    "    #outfile.close()\n",
    "    return numb,mail_lists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:40:18 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Looking for messages from 'https://lists.opendaylight.org/pipermail/aalldp-dev/' since 1970-01-01 00:00:00+00:00\n",
      "2018-07-18 14:40:18 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Downloading mboxes from 'https://lists.opendaylight.org/pipermail/aalldp-dev/' to since 1970-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime/mailing_lists.csv Place\n",
      "yeah\n",
      "Link,mail_list\n",
      "\n",
      "https://lists.opendaylight.org/pipermail/,\"aalldp-dev\"\n",
      "\n",
      "['aalldp-dev', 'archetypes-dev'] mail_list\n",
      "{'aalldp-dev': False, 'archetypes-dev': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:40:21 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO 2/2 MBoxes downloaded\n",
      "2018-07-18 14:40:21 keanu-Inspiron-5567 perceval.backends.core.mbox[19902] INFO Done. 6/6 messages fetched; 0 ignored\n",
      "2018-07-18 14:40:21 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Fetch process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "getting\n",
      "yep\n",
      "got-em\n",
      "4\n",
      "['aalldp-dev']\n",
      "2018-07-06 18:39:58\n",
      "File uploaded  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:40:31 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Looking for messages from 'https://lists.opendaylight.org/pipermail/archetypes-dev/' since 1970-01-01 00:00:00+00:00\n",
      "2018-07-18 14:40:31 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Downloading mboxes from 'https://lists.opendaylight.org/pipermail/archetypes-dev/' to since 1970-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mailing List Job uploaded\n",
      "Finished\n",
      "Created File aalldp-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:40:34 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO 1/1 MBoxes downloaded\n",
      "2018-07-18 14:40:34 keanu-Inspiron-5567 perceval.backends.core.mbox[19902] INFO Done. 2/2 messages fetched; 0 ignored\n",
      "2018-07-18 14:40:34 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Fetch process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "1\n",
      "['archetypes-dev']\n",
      "File uploaded  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:40:44 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Looking for messages from 'https://lore.kernel.org/lkml/' since 2013-01-01 20:37:11\n",
      "2018-07-18 14:40:44 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Downloading mboxes from 'https://lore.kernel.org/lkml/' to since 2013-01-01 20:37:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mailing List Job uploaded\n",
      "Finished\n",
      "Created File archetypes-dev\n",
      "{'aalldp-dev': 'new', 'archetypes-dev': 'new'}\n",
      "Finished downloading files\n",
      "['lkml'] mail_list\n",
      "{'lkml': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 14:43:17 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO 92/92 MBoxes downloaded\n",
      "2018-07-18 14:43:17 keanu-Inspiron-5567 perceval.backends.core.mbox[19902] INFO Done. 2/2 messages fetched; 0 ignored\n",
      "2018-07-18 14:43:17 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Fetch process completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "1\n",
      "['lkml']\n",
      "File uploaded  4\n",
      "Mailing List Job uploaded\n",
      "Finished\n",
      "Created File lkml\n",
      "{'lkml': 'new'}\n",
      "Finished downloading files\n"
     ]
    }
   ],
   "source": [
    "# create an Augur application so we can test our function\n",
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "Piper, path= augurApp.piper()\n",
    "print(path,\"Place\")\n",
    "if(not os.path.exists(path)):\n",
    "    file = open(path, \"w+\")\n",
    "else:\n",
    "    file = open(path, \"r\")\n",
    "    print(\"yeah\")\n",
    "if (os.stat(path).st_size == 0):\n",
    "    file.write(\"Link,mail_list\\n\")\n",
    "    file.write(\"https://lists.opendaylight.org/pipermail/,\\\"aalldp-dev\\\"\\n\")\n",
    "    file.write(\"https://lists.opendaylight.org/pipermail/,\\\"archetypes-dev\\\"\\n\")\n",
    "    print(\"Please enter the mailing lists and the links for them please\")\n",
    "    print(\"Going to the default mailing lists\")\n",
    "\n",
    "count = 0\n",
    "for line in file:\n",
    "    print(line)\n",
    "    count+=1\n",
    "    if(count == 2):\n",
    "        break\n",
    "if(count == 2):\n",
    "    #print(pd.read_csv(path))\n",
    "    df = pd.read_csv(path)\n",
    "    groups = df.groupby('Link').groups\n",
    "    for group in groups:\n",
    "        link = group\n",
    "        mail_list = (df.loc[df['Link'] == group]['mail_list']).tolist()\n",
    "        print(mail_list,\"mail_list\")            \n",
    "        #link = \"https://lists.opendaylight.org/pipermail/\"\n",
    "        #mail = [\"aalldp-dev\",\"alto-dev\",\"archetypes-dev\"]\n",
    "        #mail = [\"aalldp-dev\",\"alto-dev\",\"archetypes-dev\",\"dev\"]\n",
    "        #mail = [\"aalldp-dev\",\"archetypes-dev\",\"alto-dev\"]\n",
    "        #mail = [\"aalldp-dev\",\"archetypes-dev\"]\n",
    "        mail_check = {key:False for key in mail_list}\n",
    "        print(mail_check)\n",
    "        #print(os.getcwd())\n",
    "        file = \"mail_list\"\n",
    "        path = \"/augur/data/archive-\" \n",
    "        #numb = 0\n",
    "        for x in range(len(mail_list)):\n",
    "            #print(link+mail[x])\n",
    "            if(mail_list[x] not in df1['project'].values ):\n",
    "                mail_check[mail_list[x]] = 'new'\n",
    "                #print(os.getcwd())\n",
    "                #print(os.path.join(os.getcwd() + path+'.json'))\n",
    "                place = os.path.join(os.getcwd() + path + mail_list[x] +'.json')           \n",
    "                repo = Pipermail(url = link+ mail_list[x] + \"/\",dirpath=\"tmp/archives_\"+mail_list[x])\n",
    "                #print(\"Broken\")\n",
    "                #break\n",
    "                #print(repo)\n",
    "                outfile = open(place,\"w+\")\n",
    "                numb,mail_lists = write_message(repo,'new',mail_check,mail_list[x],connect.db,res,session,\\\n",
    "                                     [mail_list[x]],numb,mail_lists)\n",
    "                print(\"Created File\",mail_list[x])\n",
    "            else:\n",
    "                last_updatedSQL = s.sql.text(\"\"\"SELECT last_message_date FROM \n",
    "                mailing_list_jobs WHERE project = \"\"\" +  \"'\" + mail_list[x] + \"'\")\n",
    "                last_updated_df = pd.read_sql(last_updatedSQL, connect.db)\n",
    "                time = (last_updated_df['last_message_date'])  \n",
    "                time = time.astype(object)\n",
    "                place = os.path.join(os.getcwd() + path + 'temp_' + mail_list[x] +'.json')       \n",
    "                repo = Pipermail(url = link+ mail_list[x] + \"/\",dirpath=\"tmp/archives_\"+mail_list[x])\n",
    "                outfile = open(place,\"w+\")\n",
    "                print(time[0])\n",
    "                print(type(time[0]))\n",
    "                numb,mail_lists = write_message(repo,'not_new',mail_check,mail_list[x],connect.db,\\\n",
    "                              res,session,[mail_list[x]],numb,mail_lists,time[0])\n",
    "                print(\"Checking to see for updated messages\")\n",
    "        print(mail_check)\n",
    "        print(\"Finished downloading files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Base = declarative_base(connect.db)\\nclass table(Base):\\n    __tablename__ = 'mailing_list_jobs'\\n    __table_args__={'autoload':True}\\n    \\nSession = sessionmaker(bind=connect.db)\\nsession = Session()\\nres = session.query(table).all()\\n\\nPiper.make(connect.db,mail_check,mail_list,mail_lists,res,session)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Base = declarative_base(connect.db)\n",
    "class table(Base):\n",
    "    __tablename__ = 'mailing_list_jobs'\n",
    "    __table_args__={'autoload':True}\n",
    "    \n",
    "Session = sessionmaker(bind=connect.db)\n",
    "session = Session()\n",
    "res = session.query(table).all()\n",
    "\n",
    "Piper.make(connect.db,mail_check,mail_list,mail_lists,res,session)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(mail_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 15:45:08 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Looking for messages from 'https://kernel.googlesource.com/pub/scm/public-inbox/vger.kernel.org/lkml/0' since 2018-07-01 20:37:11\n",
      "2018-07-18 15:45:08 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Downloading mboxes from 'https://kernel.googlesource.com/pub/scm/public-inbox/vger.kernel.org/lkml/0' to since 2018-07-01 20:37:11\n",
      "2018-07-18 15:45:09 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO 0/0 MBoxes downloaded\n",
      "2018-07-18 15:45:09 keanu-Inspiron-5567 perceval.backends.core.mbox[19902] INFO Done. 0/0 messages fetched; 0 ignored\n",
      "2018-07-18 15:45:09 keanu-Inspiron-5567 perceval.backends.core.pipermail[19902] INFO Fetch process completed\n"
     ]
    }
   ],
   "source": [
    "repo = Pipermail(url=\"https://kernel.googlesource.com/pub/scm/public-inbox/vger.kernel.org/lkml/0\",\\\n",
    "                 dirpath=\"tmp/archives/temp1\")\n",
    "di = {}\n",
    "for message in repo.fetch(from_date = Piper.convert_date(\"Thu, 1 Jul 2018 20:37:11 +0000\")):\n",
    "    print(message)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#di[0]['data']['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dict = {}\\ndi1 = {0:2}\\ndict[0] = 0\\nprint(dict)\\ndict['b'] = 1\\nprint(dict)\\ndict['d'] = di1\\nprint(dict)\\nprint(dict[0])\\nprint(len(dict))\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dict = {}\n",
    "di1 = {0:2}\n",
    "dict[0] = 0\n",
    "print(dict)\n",
    "dict['b'] = 1\n",
    "print(dict)\n",
    "dict['d'] = di1\n",
    "print(dict)\n",
    "print(dict[0])\n",
    "print(len(dict))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (augur)",
   "language": "python",
   "name": "augur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
