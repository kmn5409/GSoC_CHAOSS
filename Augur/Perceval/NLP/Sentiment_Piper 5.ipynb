{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import os,json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize \n",
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "import augur\n",
    "import sqlalchemy as s\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import table, column, select, update, insert\n",
    "from sqlalchemy import MetaData\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#pip install twython\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(\"notebooks\" not in os.getcwd()):\n",
    "    os.chdir(\"notebooks\")\n",
    "augurApp = augur.Application('../augur.config.json')\n",
    "connect = augurApp.ghtorrentplus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['issue_response_time', 'mail_lists', 'mail_lists_sentiment', 'mailing_list_jobs', 'sentiment_scores', 'table_new']\n"
     ]
    }
   ],
   "source": [
    "table_names = s.inspect(connect.db).get_table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          project\n",
      "0      aalldp-dev\n",
      "1  archetypes-dev\n",
      "2        announce\n"
     ]
    }
   ],
   "source": [
    "if(\"mailing_list_jobs\" in table_names):\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM mailing_list_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, connect.db)\n",
    "    print(df1)\n",
    "    val = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aalldp-dev Mailing List\n",
      "Here!!!!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "archetypes-dev Mailing List\n",
      "Here!!!!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "announce Mailing List\n",
      "Here!!!!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "col = 'score','sentiment'\n",
    "df3 = pd.DataFrame(columns = col)\n",
    "for i in df1['project'].values:\n",
    "    print(i,\"Mailing List\")\n",
    "    SQL = s.sql.text(\"\"\"SELECT subject,message_id,message_text,message_parts_tot \n",
    "    FROM mail_lists WHERE mailing_list = \"\"\" +  \"'\" + i + \"'\")\n",
    "    df2 = pd.read_sql(SQL, connect.db)\n",
    "    #print(df2)\n",
    "    grouped = df2.groupby('message_id').groups\n",
    "    print(\"Here!!!!\")\n",
    "    #print(\"\\n\\n\",\"-\"*70,\"\\n\\n\")\n",
    "    for group in grouped:\n",
    "        parts = 0\n",
    "        numb = len(df2.loc[df2['message_id'] == group]['message_parts_tot'].tolist())\n",
    "        message = (df2.loc[df2['message_id'] == group]['message_text']).tolist()\n",
    "        message_text = ''.join(message)\n",
    "        sentences = tokenizer.tokenize(message_text)\n",
    "        compound = parts = 0\n",
    "        sentiment = \"Positive\"\n",
    "        for sentence in sentences:\n",
    "            scores = sid.polarity_scores(sentence)\n",
    "            compound+= scores['compound']\n",
    "            parts+=1\n",
    "        avg_score = compound/parts\n",
    "        if(avg_score == 0):\n",
    "            sentiment = \"Neutral\"\n",
    "        elif(avg_score < 0):\n",
    "            sentiment = \"Negative\"\n",
    "        #print(message)\n",
    "        print(\"\\n\\n\")\n",
    "        #print(\"Score\",avg_score)\n",
    "        print(\"\\n\\n\\n\")\n",
    "        for i in range(numb):\n",
    "            li = [ [avg_score, sentiment] ]\n",
    "            df_temp = pd.DataFrame(li,columns = col)\n",
    "            #print(df_temp['score'])\n",
    "            df3 = df3.append(df_temp)\n",
    "            #print(df3)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    augurmsgID     score sentiment\n",
      "0            1  0.140263  Positive\n",
      "1            2  0.140263  Positive\n",
      "2            3  0.624650  Positive\n",
      "3            4  0.624650  Positive\n",
      "4            5  0.148000  Positive\n",
      "5            6  0.148000  Positive\n",
      "6            7  0.285950  Positive\n",
      "7            8  0.285950  Positive\n",
      "8            9  0.254578  Positive\n",
      "9           10  0.254578  Positive\n",
      "10          11  0.405283  Positive\n",
      "11          12  0.405283  Positive\n",
      "12          13  0.172427  Positive\n",
      "13          14  0.172427  Positive\n",
      "14          15  0.264620  Positive\n",
      "15          16  0.264620  Positive\n",
      "16          17  0.350940  Positive\n",
      "17          18  0.350940  Positive\n",
      "18          19  0.191714  Positive\n",
      "19          20  0.191714  Positive\n",
      "20          21  0.170033  Positive\n",
      "21          22  0.170033  Positive\n",
      "22          23  0.344075  Positive\n",
      "23          24  0.344075  Positive\n",
      "24          25  0.481638  Positive\n",
      "25          26  0.481638  Positive\n"
     ]
    }
   ],
   "source": [
    "if(len(list(df3)) == 2):\n",
    "    df3.reset_index(level=0, inplace=True)\n",
    "    df3.columns = ['augurmsgID','score','sentiment']\n",
    "    for i in range(len(df3['augurmsgID'])):\n",
    "        df3.loc[i,'augurmsgID'] = i+1\n",
    "print(df3)\n",
    "\n",
    "#for i in range(len(df4['score'])):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_sql(name='sentiment_scores',con=connect.db,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session = sessionmaker(connect.db)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df7 = pd.read_sql(\"\"\"SELECT\n",
    "\n",
    " mail_lists.augurmsgID as augurmsgID, \n",
    " mail_lists.backend_name as backend_name,\n",
    " mail_lists.project as project,\n",
    " mail_lists.mailing_list as mailing_list,\n",
    " mail_lists.category as category,\n",
    " mail_lists.message_part as message_part,\n",
    " mail_lists.message_parts_tot as message_parts_tot,\n",
    " mail_lists.subject as subject,\n",
    " mail_lists.date as date,\n",
    " mail_lists.message_from as message_from,\n",
    " mail_lists.message_id as message_id,\n",
    " sentiment_scores.score as score,\n",
    " sentiment_scores.sentiment as sentiment,\n",
    " mail_lists.message_text as message_text\n",
    "\n",
    "FROM mail_lists,sentiment_scores\n",
    "\n",
    "WHERE mail_lists.augurmsgID \n",
    "= sentiment_scores.augurmsgID;\"\"\",connect.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    augurmsgID backend_name  \\\n",
      "0            1    Pipermail   \n",
      "1            2    Pipermail   \n",
      "2            3    Pipermail   \n",
      "3            4    Pipermail   \n",
      "4            5    Pipermail   \n",
      "5            6    Pipermail   \n",
      "6            7    Pipermail   \n",
      "7            8    Pipermail   \n",
      "8            9    Pipermail   \n",
      "9           10    Pipermail   \n",
      "10          11    Pipermail   \n",
      "11          12    Pipermail   \n",
      "12          13    Pipermail   \n",
      "13          14    Pipermail   \n",
      "14          15    Pipermail   \n",
      "15          16    Pipermail   \n",
      "16          17    Pipermail   \n",
      "17          18    Pipermail   \n",
      "18          19    Pipermail   \n",
      "19          20    Pipermail   \n",
      "20          21    Pipermail   \n",
      "21          22    Pipermail   \n",
      "22          23    Pipermail   \n",
      "23          24    Pipermail   \n",
      "24          25    Pipermail   \n",
      "25          26    Pipermail   \n",
      "\n",
      "                                              project    mailing_list  \\\n",
      "0   https://lists.opendaylight.org/pipermail/aalld...      aalldp-dev   \n",
      "1   https://lists.opendaylight.org/pipermail/aalld...      aalldp-dev   \n",
      "2   https://lists.opendaylight.org/pipermail/aalld...      aalldp-dev   \n",
      "3   https://lists.opendaylight.org/pipermail/aalld...      aalldp-dev   \n",
      "4   https://lists.opendaylight.org/pipermail/arche...  archetypes-dev   \n",
      "5   https://lists.opendaylight.org/pipermail/arche...  archetypes-dev   \n",
      "6   https://lists.opendaylight.org/pipermail/arche...  archetypes-dev   \n",
      "7   https://lists.opendaylight.org/pipermail/arche...  archetypes-dev   \n",
      "8   https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "9   https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "10  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "11  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "12  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "13  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "14  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "15  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "16  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "17  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "18  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "19  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "20  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "21  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "22  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "23  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "24  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "25  https://lists.opendaylight.org/pipermail/annou...        announce   \n",
      "\n",
      "   category  message_part  message_parts_tot  \\\n",
      "0   message             1                  2   \n",
      "1   message             2                  2   \n",
      "2   message             1                  2   \n",
      "3   message             2                  2   \n",
      "4   message             1                  2   \n",
      "5   message             2                  2   \n",
      "6   message             1                  2   \n",
      "7   message             2                  2   \n",
      "8   message             1                  2   \n",
      "9   message             2                  2   \n",
      "10  message             1                  2   \n",
      "11  message             2                  2   \n",
      "12  message             1                  2   \n",
      "13  message             2                  2   \n",
      "14  message             1                  2   \n",
      "15  message             2                  2   \n",
      "16  message             1                  2   \n",
      "17  message             2                  2   \n",
      "18  message             1                  2   \n",
      "19  message             2                  2   \n",
      "20  message             1                  2   \n",
      "21  message             2                  2   \n",
      "22  message             1                  2   \n",
      "23  message             2                  2   \n",
      "24  message             1                  2   \n",
      "25  message             2                  2   \n",
      "\n",
      "                                              subject                date  \\\n",
      "0               [aalldp-dev] AALLDP Active Committers 2016-03-24 20:37:11   \n",
      "1               [aalldp-dev] AALLDP Active Committers 2016-03-24 20:37:11   \n",
      "2     [aalldp-dev] Plans for Archiving AALLDP Project 2016-03-24 20:37:08   \n",
      "3     [aalldp-dev] Plans for Archiving AALLDP Project 2016-03-24 20:37:08   \n",
      "4          [archetypes-dev] Mailing archive list test 2018-04-17 21:37:58   \n",
      "5          [archetypes-dev] Mailing archive list test 2018-04-17 21:37:58   \n",
      "6   [archetypes-dev] archetypes-dev mailing list a... 2018-04-18 09:11:16   \n",
      "7   [archetypes-dev] archetypes-dev mailing list a... 2018-04-18 09:11:16   \n",
      "8   [announce] [OpenDaylight Discuss] Fwd: [OpenDa... 2015-04-27 19:31:35   \n",
      "9   [announce] [OpenDaylight Discuss] Fwd: [OpenDa... 2015-04-27 19:31:35   \n",
      "10  [announce] [OpenDaylight Discuss] The ODL SFC ... 2015-05-05 16:55:39   \n",
      "11  [announce] [OpenDaylight Discuss] The ODL SFC ... 2015-05-05 16:55:39   \n",
      "12  [announce] [OpenDaylight TSC] [OpenDaylight Ma... 2015-05-13 02:53:05   \n",
      "13  [announce] [OpenDaylight TSC] [OpenDaylight Ma... 2015-05-13 02:53:05   \n",
      "14    [announce] CFP for ONS OpenDaylight Mini Summit 2016-01-27 17:59:09   \n",
      "15    [announce] CFP for ONS OpenDaylight Mini Summit 2016-01-27 17:59:09   \n",
      "16  [announce] Please Take & Share 2016 ODL User S... 2016-02-01 17:57:57   \n",
      "17  [announce] Please Take & Share 2016 ODL User S... 2016-02-01 17:57:57   \n",
      "18  [announce] Reminder - OpenDaylight Summit CFP ... 2016-05-03 19:08:52   \n",
      "19  [announce] Reminder - OpenDaylight Summit CFP ... 2016-05-03 19:08:52   \n",
      "20  [announce] This Week's ODL TWS is on Carbon Pl... 2016-05-09 16:50:53   \n",
      "21  [announce] This Week's ODL TWS is on Carbon Pl... 2016-05-09 16:50:53   \n",
      "22  [announce] OpenDaylight Boron Hackfest - Book ... 2016-06-06 16:11:09   \n",
      "23  [announce] OpenDaylight Boron Hackfest - Book ... 2016-06-06 16:11:09   \n",
      "24  [announce] There is no longer any gates for re... 2017-04-26 22:27:53   \n",
      "25  [announce] There is no longer any gates for re... 2017-04-26 22:27:53   \n",
      "\n",
      "                                         message_from  \\\n",
      "0                         An.Ho at huawei.com (An Ho)   \n",
      "1                         An.Ho at huawei.com (An Ho)   \n",
      "2                         An.Ho at huawei.com (An Ho)   \n",
      "3                         An.Ho at huawei.com (An Ho)   \n",
      "4   agrimberg at linuxfoundation.org (Andrew Grimb...   \n",
      "5   agrimberg at linuxfoundation.org (Andrew Grimb...   \n",
      "6         vorburger at redhat.com (Michael Vorburger)   \n",
      "7         vorburger at redhat.com (Michael Vorburger)   \n",
      "8             chrispriceab at gmail.com (Chris Price)   \n",
      "9             chrispriceab at gmail.com (Chris Price)   \n",
      "10        abhijitkoss at gmail.com (Abhijit Kumbhare)   \n",
      "11        abhijitkoss at gmail.com (Abhijit Kumbhare)   \n",
      "12                uri.elzur at intel.com (Elzur, Uri)   \n",
      "13                uri.elzur at intel.com (Elzur, Uri)   \n",
      "14           probb at linuxfoundation.org (Phil Robb)   \n",
      "15           probb at linuxfoundation.org (Phil Robb)   \n",
      "16           probb at linuxfoundation.org (Phil Robb)   \n",
      "17           probb at linuxfoundation.org (Phil Robb)   \n",
      "18           probb at linuxfoundation.org (Phil Robb)   \n",
      "19           probb at linuxfoundation.org (Phil Robb)   \n",
      "20           probb at linuxfoundation.org (Phil Robb)   \n",
      "21           probb at linuxfoundation.org (Phil Robb)   \n",
      "22           probb at linuxfoundation.org (Phil Robb)   \n",
      "23           probb at linuxfoundation.org (Phil Robb)   \n",
      "24           probb at linuxfoundation.org (Phil Robb)   \n",
      "25           probb at linuxfoundation.org (Phil Robb)   \n",
      "\n",
      "                                           message_id     score sentiment  \\\n",
      "0   <EEEA408CE50B48498B9F866085AEF2912FAEEAAD@SJCE...  0.140263  Positive   \n",
      "1   <EEEA408CE50B48498B9F866085AEF2912FAEEAAD@SJCE...  0.140263  Positive   \n",
      "2   <EEEA408CE50B48498B9F866085AEF2912FAEEAA0@SJCE...  0.624650  Positive   \n",
      "3   <EEEA408CE50B48498B9F866085AEF2912FAEEAA0@SJCE...  0.624650  Positive   \n",
      "4   <34dc81cb-f265-875a-ba4c-eac4fc664c6c@linuxfou...  0.148000  Positive   \n",
      "5   <34dc81cb-f265-875a-ba4c-eac4fc664c6c@linuxfou...  0.148000  Positive   \n",
      "6   <CACeyj_G0CPafJwN1i8-aLMVDxS9wNggUKzDc-WsWOD-p...  0.285950  Positive   \n",
      "7   <CACeyj_G0CPafJwN1i8-aLMVDxS9wNggUKzDc-WsWOD-p...  0.285950  Positive   \n",
      "8             <D1645AF0.34A88%chrispriceab@gmail.com>  0.254578  Positive   \n",
      "9             <D1645AF0.34A88%chrispriceab@gmail.com>  0.254578  Positive   \n",
      "10  <CAHce=85u1gL8ZEaPnRmBrRpegP3zW=urRMF+Ty8C4KFV...  0.405283  Positive   \n",
      "11  <CAHce=85u1gL8ZEaPnRmBrRpegP3zW=urRMF+Ty8C4KFV...  0.405283  Positive   \n",
      "12  <7E05C330D7FD6D4FAD0728C46B89958581C4F687@ORSM...  0.172427  Positive   \n",
      "13  <7E05C330D7FD6D4FAD0728C46B89958581C4F687@ORSM...  0.172427  Positive   \n",
      "14  <CAFHD1sMV9Jk5pCkegCBkC+5MSSG7ipZE5-fe9jHF-JHK...  0.264620  Positive   \n",
      "15  <CAFHD1sMV9Jk5pCkegCBkC+5MSSG7ipZE5-fe9jHF-JHK...  0.264620  Positive   \n",
      "16  <CAFHD1sOXwHvzceFzZMnmG1QAW1F9-naw1rTehF9mwpd=...  0.350940  Positive   \n",
      "17  <CAFHD1sOXwHvzceFzZMnmG1QAW1F9-naw1rTehF9mwpd=...  0.350940  Positive   \n",
      "18  <CAFHD1sNr6yRSROLf08o+Uph0GwyEg--MTdAk9yGgq2Nn...  0.191714  Positive   \n",
      "19  <CAFHD1sNr6yRSROLf08o+Uph0GwyEg--MTdAk9yGgq2Nn...  0.191714  Positive   \n",
      "20  <CAFHD1sPCHuu4NtUm_oUCB=8aLOa4KS6Zu1bkrFJ1a9ba...  0.170033  Positive   \n",
      "21  <CAFHD1sPCHuu4NtUm_oUCB=8aLOa4KS6Zu1bkrFJ1a9ba...  0.170033  Positive   \n",
      "22  <CAFHD1sPUN-pYhFCweBh_2hQx4d927tn=9jCJfJASKxEu...  0.344075  Positive   \n",
      "23  <CAFHD1sPUN-pYhFCweBh_2hQx4d927tn=9jCJfJASKxEu...  0.344075  Positive   \n",
      "24  <CAFHD1sPnkqT6_QhXdsG-gTp8obEWKv8a+ar6EmFqC1Lo...  0.481638  Positive   \n",
      "25  <CAFHD1sPnkqT6_QhXdsG-gTp8obEWKv8a+ar6EmFqC1Lo...  0.481638  Positive   \n",
      "\n",
      "                                         message_text  \n",
      "0   Hi Brian Kaczynski <kaczynskib at avaya.com>, ...  \n",
      "1   this email to indicate that you are still an a...  \n",
      "2   Hi AALLDP Team,\\n\\n\\n\\n1. Does your project ha...  \n",
      "3    for any future active development, project co...  \n",
      "4   This is just a test.\\n\\n-- \\nAndrew J Grimberg...  \n",
      "5   --------- next part --------------\\nA non-text...  \n",
      "6   Hello archetypians,\\n\\nJust to let you all kno...  \n",
      "7   es-dev/ works now (thanks\\nAndy!).\\n\\nJust in ...  \n",
      "8   I?ll be cheering and shouting from the back of...  \n",
      "9   alks from the community!!!\\n\\n/ Chris\\n\\nFrom:...  \n",
      "10  Great!\\n\\nOn Tue, May 5, 2015 at 9:54 AM, Brad...  \n",
      "11  rote:\\n\\n>\\n> I just presented to the OPNFV TS...  \n",
      "12  Phil\\n\\nSorry for missing out on this. Was thi...  \n",
      "13   tsc-bounces at lists.opendaylight.org [mailto...  \n",
      "14  Hey OpenDaylight Community:\\n\\n\\nWe will be ru...  \n",
      "15  tworking Summit the week of March 14th in Sant...  \n",
      "16  Hello OpenDaylight User Community:\\n\\nThe ODL ...  \n",
      "17  User Survey*\\nto collect data on where, why an...  \n",
      "18  Hey Folks:\\n\\n\\nThis is a friendly reminder th...  \n",
      "19  ation.org/events/opendaylight-summit> CFP will...  \n",
      "20  Hey Folks:\\n\\nJust a reminder that at the top ...  \n",
      "21  iscussing Carbon Release planning and what cha...  \n",
      "22  Hi Everyone,\\n\\nOpenDaylight will host the nex...  \n",
      "23  3.hilton.com/en/hotels/california/doubletree-b...  \n",
      "24  Hello Annie Lara and Casey:\\n\\nI just want to ...  \n",
      "25  e\\nregistering for the F2F in NJ next week.\\n\\...  \n"
     ]
    }
   ],
   "source": [
    "print(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df7.to_sql(name='mail_lists_sentiment',con=connect.db,if_exists='replace',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (augur)",
   "language": "python",
   "name": "augur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
