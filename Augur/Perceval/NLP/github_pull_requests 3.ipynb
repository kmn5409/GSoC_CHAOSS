{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from perceval.backends.core.github import GitHub\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import dateutil.tz\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy as s\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import augur\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "First loads the users data from 'augur.config.json' so will take the Database information (e.g. name of database, port of database). Then connects to the database using augur.App.github_issues() and takes the details of the database and connects to to the database using charset 'utf8'. It also makes a connection to piper_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(\"notebooks\" not in os.getcwd()):\n",
    "    os.chdir(\"notebooks\")\n",
    "augurApp = augur.Application('../augur.config.json')\n",
    "connect,list1,path = augurApp.github_issues()\n",
    "token = list1[5]\n",
    "DB_STR = 'mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8'.format(\n",
    "            list1[0], list1[1], list1[2],\\\n",
    "            list1[3], list1[4]\n",
    "        )\n",
    "db = s.create_engine(DB_STR)\n",
    "Piper, path= augurApp.piper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect:\n",
    "\n",
    "Queries what tables are in the database and determines if 'github_pull_requests_2' is there if it is then 'git_repos' is set as 'True', if it isn't there 'git_repos' is set as 'False'. Then we determine what git repositories are in 'github_issues_repo_jobs' and determine how many rows are in it. If 'github_pull_request_repo_jobs' is not in the database it is created and the column 'augurlistID' is set as the primary key. We then add a connection to 'github_pull_request_repo_jobs' so that we can change the column 'last_run' if new messages were downloaded for a git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github_issues', 'github_issues_2', 'github_issues_repo_jobs', 'github_issues_sentiment_scores', 'github_pull_requests', 'github_pull_requests_sentiment_scores', 'github_pull_requests_sentiment_scores_2', 'issue_response_time', 'mail_lists', 'mail_lists_sentiment_scores', 'mailing_list_jobs']\n",
      "Created Table\n"
     ]
    }
   ],
   "source": [
    "table_names = s.inspect(db).get_table_names()\n",
    "print(table_names)\n",
    "val = False\n",
    "#mail_lists = True\n",
    "git_repos = True\n",
    "numb = 0\n",
    "item = 1\n",
    "columns2 = \"augurlistID\",\"backend_name\",\"github_repo_url\",\"project\",\"last_run\"\n",
    "df_mail_list = pd.DataFrame(columns=columns2)\n",
    "if(\"github_pull_requests_2\" not in table_names):\n",
    "    #mail_lists = False\n",
    "    git_repos = False\n",
    "else:\n",
    "    SQL = s.sql.text(\"\"\"SELECT COUNT(*) FROM github_pull_requests_2\"\"\")\n",
    "    df7 = pd.read_sql(SQL, db)\n",
    "    augurmsgID = int(df7.values)+1\n",
    "    item = augurmsgID\n",
    "if(\"github_pull_request_repo_jobs\" in table_names):\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM github_pull_request_repo_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, db)\n",
    "    print(df1)\n",
    "    val = True\n",
    "    val = db.engine.execute(\"\"\"SELECT augurlistID FROM \n",
    "                                   github_pull_request_repo_jobs\n",
    "                                   ORDER BY augurlistID DESC LIMIT 1\"\"\")\n",
    "    for i in val:\n",
    "        numb = i['augurlistID']\n",
    "    \n",
    "else:\n",
    "    df_mail_list.to_sql(name=\"github_pull_request_repo_jobs\",con=db,if_exists='replace',index=False,\n",
    "                        dtype={'augurlistID': s.types.Integer(),\n",
    "                               'backend_name': s.types.VARCHAR(length=300),\n",
    "                               'github_repo_url': s.types.VARCHAR(length=300),\n",
    "                               'project': s.types.VARCHAR(length=300),\n",
    "                               'last_run': s.types.DateTime()\n",
    "                        })\n",
    "    lists_createdSQL = s.sql.text(\"\"\"SELECT project FROM github_pull_request_repo_jobs\"\"\")\n",
    "    df1 = pd.read_sql(lists_createdSQL, db)\n",
    "    db.execute(\"ALTER TABLE github_pull_request_repo_jobs ADD PRIMARY KEY (augurlistID)\")\n",
    "    print(\"Created Table\")\n",
    "Base = declarative_base(db)\n",
    "class table(Base):\n",
    "    __tablename__ = 'github_pull_request_repo_jobs'\n",
    "    __table_args__={'autoload':True}\n",
    "    \n",
    "Session = sessionmaker(bind=db)\n",
    "session = Session()\n",
    "res = session.query(table).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file:\n",
    "\n",
    "Determines if the file with the git repositories were created, if not it writes a set of default git repositories (to show how the program would work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime/git_repos.csv\n",
      "Please enter the mailing lists and the links for them please\n",
      "Going to the default mailing lists\n"
     ]
    }
   ],
   "source": [
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "connect,list1,path = augurApp.github_issues()\n",
    "print(path)\n",
    "if(not os.path.exists(path)):\n",
    "    file = open(path, \"w+\")\n",
    "else:\n",
    "    file = open(path, \"r\")\n",
    "    print(\"yeah\")\n",
    "if (os.stat(path).st_size == 0):\n",
    "    file.write(\"owner,repo_url\\n\")\n",
    "    file.write(\"chaoss,\\\"whitepaper\\\"\\n\")\n",
    "    file.write(\"OSSHealth,\\\"ResearchProject\\\"\\n\")\n",
    "    #file.write(\"https://lists.opendaylight.org/pipermail/,\\\"archetypes-dev\\\"\\n\")\n",
    "    print(\"Please enter the mailing lists and the links for them please\")\n",
    "    print(\"Going to the default mailing lists\")\n",
    "\n",
    "count = 0\n",
    "for line in file:\n",
    "    print(line)\n",
    "    count+=1\n",
    "    if(count == 2):\n",
    "        break\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration through github repositories\n",
    "\n",
    "This first reads the git repositories stored in 'path' and we also get the current date 'today'. We then create a dataframe 'github_pull_requests_2' that will store all the comments under a pull request and the pull requrest itself. Grouping the pull request by owner we iterate through the different repositories and then iterate over the messages for a particular pull request. We then pull the  data from GitHub and we determine if the repository is stored in 'github_pull_request_repo_jobs', if it is we set 'new' to 'True' and store that repository so it can be added to the table 'github_pull_request_repo_jobs and 'froms' is set as 'None'. If it is in 'github_pull_request_repo_jobs' we set today's date to 'last_run' for the repository in 'github_pull_request_repo_jobs' and 'froms' is set as today's date.\n",
    "\n",
    "We then go about downloading the github pull requests for a particular repository, the 'from_date' is set as 'froms'. We then convert pull requests to a format that can be uploaded to the datebase. If the git repository is stored in 'github_pull_request_repo_jobs' then only the pull requests that occur after the date stored in 'last_run' is uploaded. If the git repository isn't in the database all the issues are uploaded. We finally upload the git repositories information to the table 'github_pull_request_repo_jobs'. Since github has a limit as to how much data can be downloaded, if a large repository with a number of pull requests is being downloaded the program will run for hours, since the Rate limit must be reset which takes around an hour each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-07 10:31:44 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/GeorgLink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-07 10:31:45 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/howderek\n",
      "2018-08-07 10:31:46 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/germonprez\n",
      "2018-08-07 10:31:49 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/bkeepers\n",
      "2018-08-07 10:31:49 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/downeym\n",
      "2018-08-07 10:31:50 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/abuhman\n",
      "2018-08-07 10:31:51 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/sgoggins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broken\n",
      "Total Number of pull requests:  29\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-07 10:32:01 keanu-Inspiron-5567 root[13012] INFO Getting info for https://api.github.com/users/rpaik\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broken\n",
      "Total Number of pull requests:  35\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "owner,repo_url\n",
    "torvalds,\"linux\"\n",
    "nodejs,\"CTC\"\n",
    "nodejs,\"TSC\"\n",
    "'''\n",
    "\n",
    "'''\n",
    "owner,repo_url\n",
    "chaoss,\"whitepaper\"\n",
    "OSSHealth,\"ResearchProject\"\n",
    "'''\n",
    "k=0\n",
    "#for issues in repo.fetch(from_date=date):\n",
    "columns1 = 'augurmsgID',\"backend_name\",'repo_link',\"owner\",\"repo\",\"subject\",\\\n",
    "          \"status\",\"category\",\"pull_request_number\",\"date\",\\\n",
    "          \"pull_request_id\",\"user\",\"body\"\n",
    "df = pd.DataFrame(columns=columns1)\n",
    "item = 1\n",
    "df.to_sql(name=\"github_pull_requests_2\", con=db,\\\n",
    "          if_exists='append',index=False,\n",
    "           dtype={'augurmsgID': s.types.Integer,#0\n",
    "                  'backend_name': s.types.VARCHAR(length=300),#1\n",
    "                  'repo_link': s.types.VARCHAR(length=300),#2\n",
    "                  'owner': s.types.VARCHAR(length=300),#3\n",
    "                  'repo': s.types.VARCHAR(length=300),#4\n",
    "                  'subject': s.types.VARCHAR(length=300),#5\n",
    "                  'status': s.types.VARCHAR(length=10),#6\n",
    "                  'category': s.types.VARCHAR(length=1000),#7\n",
    "                  'pull_request_number': s.types.Integer,#8\n",
    "                  'date': s.types.DateTime(),#9\n",
    "                  'pull_request_id': s.types.Integer,#10\n",
    "                  'user': s.types.VARCHAR(length=100),#11\n",
    "                  'body':s.types.TEXT#12              \n",
    "           })\n",
    "\n",
    "df5 = pd.read_csv(path)\n",
    "groups = df5.groupby('owner').groups\n",
    "today = strftime(\"%a, %d %b %Y %H:%M:%S +0000\", gmtime())\n",
    "x = 0\n",
    "new = False\n",
    "for group in groups:\n",
    "    own = group\n",
    "    repo_url = (df5.loc[df5['owner'] == group]['repo_url']).tolist()\n",
    "    for y in repo_url:        \n",
    "        repo = GitHub(owner=own,repository=y,api_token=token,\\\n",
    "                      sleep_for_rate=True,min_rate_to_sleep=500)\n",
    "        inside = own + '/' + y\n",
    "        if(inside not in df1['project'].values):\n",
    "            new = True\n",
    "            li = [[numb,\"GitHub\",'https://github.com/' + inside, inside,Piper.convert_date(today)]]\n",
    "            df8 = pd.DataFrame(li,columns=columns2)\n",
    "            df4 = df_mail_list.append(df8)\n",
    "            df_mail_list = df4\n",
    "            numb+=1\n",
    "            froms = None\n",
    "            #continue\n",
    "        else:\n",
    "            j = 0\n",
    "            #print(today)\n",
    "            time = Piper.convert_date(today)\n",
    "            while(res[j].project!=inside):\n",
    "                #print(res[j].project)\n",
    "                j+=1\n",
    "            now = res[j].last_run\n",
    "            print(now)\n",
    "            res[j].last_run = time\n",
    "            session.commit()\n",
    "            froms = now\n",
    "            #froms = Piper.convert_date(now)\n",
    "            #continue\n",
    "            #\"Thu, 5 Mar 2018 14:57:56 +0000\"\n",
    "        for issues in repo.fetch(from_date = froms):\n",
    "            if 'pull_request' in issues['data']:\n",
    "                created = issues['data']['created_at']\n",
    "                #print(created)\n",
    "                issue_time = created[:10] + \" \" + created[11:19]\n",
    "                issue_time = dt.strptime(issue_time,\"%Y-%m-%d %H:%M:%S\")\n",
    "                text = issues['data']['body']\n",
    "                user = issues['data']['user']['login']\n",
    "                num = issues['data']['number']\n",
    "                id_num = issues['data']['id']\n",
    "                store = [item,issues['backend_name'],issues['tag'],own,y,\\\n",
    "                         issues['data']['title'],issues['data']['state'],\\\n",
    "                         \"pull_request\",num,issue_time,\\\n",
    "                         id_num,user,text]\n",
    "                df_user = pd.DataFrame([store],columns=columns1)\n",
    "                if(froms == None):\n",
    "                    df = df.append(df_user)\n",
    "                    item+=1\n",
    "                elif(issue_time > froms):\n",
    "                    df = df.append(df_user)\n",
    "                    item+=1\n",
    "                    #print(\"Yeah\")\n",
    "                for i in range(len(issues['data']['comments_data'])):\n",
    "                    created = issues['data']['comments_data'][i]\\\n",
    "                    ['created_at']\n",
    "                    issue_time = created[:10] + \" \" + created[11:19]\n",
    "                    issue_time = dt.strptime(issue_time,\"%Y-%m-%d %H:%M:%S\")\n",
    "                    temp=0\n",
    "                    store[0] = item\n",
    "                    store[8] = issues['data']['number']\n",
    "                    store[9] = issue_time\n",
    "                    store[10] = issues['data']['id']\n",
    "                    store[11] = issues['data']['comments_data'][i]\\\n",
    "                    ['user_data']['login']\n",
    "                    store[12] = issues['data']['comments_data'][i]['body']\n",
    "                    df_user = pd.DataFrame([store],columns=columns1)\n",
    "                    #print(issues['data']['comments_data'][i]\\\n",
    "                    #      ['user_data']['login'])\n",
    "                    #print(issues['data']['comments_data'][i]['body'])\n",
    "                    if(froms == None):\n",
    "                        df = df.append(df_user)\n",
    "                        item+=1\n",
    "                    elif(issue_time > froms):\n",
    "                        df = df.append(df_user)\n",
    "                        item+=1\n",
    "                        \n",
    "            if(df.shape[0] > 500):\n",
    "                db = s.create_engine(DB_STR)\n",
    "                df.to_sql(name='github_pull_requests_2', con=db,\\\n",
    "                          if_exists='append',index=False)\n",
    "                df = pd.DataFrame(columns=columns1)\n",
    "                print(\"Broken\")\n",
    "                #break\n",
    "            #print(issues['data'][''])\n",
    "            if(k%50 == 0):\n",
    "                print(k)\n",
    "            k+=1\n",
    "            #if(k == 2):\n",
    "            #    break\n",
    "        \n",
    "        #print(df)\n",
    "        if(df.shape[0] < 500):\n",
    "            db = s.create_engine(DB_STR)\n",
    "            df.to_sql(name='github_pull_requests_2', con=db,\\\n",
    "                          if_exists='append',index=False)\n",
    "            df = pd.DataFrame(columns=columns1)\n",
    "            print(\"Broken\")\n",
    "        print(\"Total Number of pull requests: \", k)\n",
    "        print(df.shape[0])\n",
    "if(new == True):\n",
    "    df_mail_list.to_sql(name='github_pull_request_repo_jobs',con=db,if_exists='append',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (augur)",
   "language": "python",
   "name": "augur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
